{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute on branch \"neurips24-plots\" \n",
    "\n",
    "# Outside of Tournesol, solidago can be installed with the following command:\n",
    "# %pip install \"git+https://github.com/tournesol-app/tournesol.git@neurips24-plots#egg=solidago&subdirectory=solidago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from solidago.pipeline import Pipeline\n",
    "from solidago.pipeline.inputs import TournesolInputFromPublicDataset\n",
    "from solidago.pipeline.outputs import PipelineOutputInMemory\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Download dataset, dated 2024-05-20\n",
    "dataset = TournesolInputFromPublicDataset(\"https://kdrive.infomaniak.com/2/app/898769/share/fd11392f-ee1d-4fd5-aec2-eac8c27a5740/files/55/download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def run_pipeline(pipeline: Pipeline, criterion: str):\n",
    "    output = PipelineOutputInMemory()\n",
    "    pipeline.run(input=dataset, criterion=criterion, output=output)\n",
    "\n",
    "    user_to_n_comparisons = defaultdict(Counter)\n",
    "    for c in dataset.get_comparisons(criteria=criterion).itertuples():\n",
    "        user_to_n_comparisons[c.user_id].update([c.entity_a, c.entity_b])\n",
    "\n",
    "    indiv_scores = output.individual_scores\n",
    "    indiv_scores[\"comparisons\"] = indiv_scores.apply(lambda s: user_to_n_comparisons[s.user_id][s.entity_id], axis=1)\n",
    "    indiv_scores[\"n_comparisons\"] = pd.cut(indiv_scores.comparisons, bins=[0, 1, 2, 4, 8, np.inf])    \n",
    "\n",
    "    global_scores = output.entity_scores\n",
    "    global_scores[\"contributors\"] = global_scores[\"entity_id\"].map(output.individual_scores.groupby(\"entity_id\")[\"user_id\"].nunique())\n",
    "    global_scores[\"n_contributors\"] = global_scores[\"contributors\"].map(lambda x: str(x) if x <= 3 else \"4+\")\n",
    "\n",
    "    return indiv_scores, global_scores\n",
    "\n",
    "def plot_individual_scores(indiv_scores, subtitle=\"\", dir=None):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    ax = sns.histplot(\n",
    "        data=indiv_scores,\n",
    "        x=\"score\",\n",
    "        hue=\"n_comparisons\",\n",
    "        hue_order=sorted(indiv_scores[\"n_comparisons\"].unique(), reverse=True),\n",
    "        palette=\"coolwarm_r\",\n",
    "        multiple=\"stack\",\n",
    "        linewidth=.5,\n",
    "        binwidth=2,\n",
    "        binrange=[-100,100],\n",
    "    )\n",
    "    ax.set_title(\"Displayed user scores $\\\\theta_{ue}^{\\\\bf display}$\\n\" + subtitle)\n",
    "    if dir is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir / f\"indiv_scores.png\", dpi=150)\n",
    "\n",
    "\n",
    "def plot_global_scores(global_scores, subtitle=\"\", dir=None):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    ax = sns.histplot(\n",
    "        data=global_scores,\n",
    "        x=\"score\",\n",
    "        hue=\"n_contributors\",\n",
    "        hue_order=sorted(global_scores[\"n_contributors\"].unique()),\n",
    "        palette=\"coolwarm\",\n",
    "        multiple=\"stack\",\n",
    "        binwidth=2,\n",
    "        binrange=[-30, 70],\n",
    "        linewidth=.5,\n",
    "    )\n",
    "    ax.set_title(\"Displayed global scores $\\\\rho_e^{\\\\bf display}$\\n\" + subtitle)\n",
    "    if dir is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(dir / f\"global_scores.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from solidago.aggregation import EntitywiseQrQuantile\n",
    "from solidago.preference_learning import UniformGBT\n",
    "from solidago.scaling import ScalingCompose, Mehestan, QuantileZeroShift, Standardize\n",
    "\n",
    "\n",
    "runs = [\n",
    "    dict(pipeline=Pipeline(), subtitle=\"default pipeline\"),\n",
    "    dict(pipeline=Pipeline(aggregation=EntitywiseQrQuantile(quantile=0.3)), subtitle=\"$ \\\\alpha = 0.3 $\"),\n",
    "    dict(pipeline=Pipeline(aggregation=EntitywiseQrQuantile(quantile=0.4)), subtitle=\"$ \\\\alpha = 0.4 $\"),\n",
    "    dict(pipeline=Pipeline(aggregation=EntitywiseQrQuantile(quantile=0.5)), subtitle=\"$ \\\\alpha = 0.5 $\"),\n",
    "    dict(pipeline=Pipeline(preference_learning=UniformGBT(prior_std_dev=1/sqrt(0.002))), subtitle=\"$ \\\\alpha_{user}^{prior} = 0.002 $\"),\n",
    "    dict(pipeline=Pipeline(preference_learning=UniformGBT(prior_std_dev=1/sqrt(0.2))), subtitle=\"$ \\\\alpha_{user}^{prior} = 0.2 $\"),\n",
    "    dict(\n",
    "        pipeline=Pipeline(scaling=ScalingCompose(Mehestan(), QuantileZeroShift(zero_quantile=0.1), Standardize())),\n",
    "        subtitle=\"$ q^{zero}_{shift} = 0.1 $\",\n",
    "    ),\n",
    "    dict(\n",
    "        pipeline=Pipeline(scaling=ScalingCompose(Mehestan(), QuantileZeroShift(zero_quantile=0.2), Standardize())),\n",
    "        subtitle=\"$ q^{zero}_{shift} = 0.2 $\",\n",
    "    ),\n",
    "    dict(\n",
    "        pipeline=Pipeline(scaling=ScalingCompose(Mehestan(), QuantileZeroShift(), Standardize(dev_quantile=0.5))),\n",
    "        subtitle=\"$ q^{sss}_{dev} = 0.5 $\",\n",
    "    ),\n",
    "    dict(\n",
    "        pipeline=Pipeline(scaling=ScalingCompose(Mehestan(), QuantileZeroShift(), Standardize(dev_quantile=0.9))),\n",
    "        subtitle=\"$ q^{sss}_{dev} = 0.9 $\",\n",
    "    ),\n",
    "    dict(pipeline=Pipeline(aggregation=EntitywiseQrQuantile(lipschitz=0.05)), subtitle=\"$ L = 0.05 $\"),\n",
    "    dict(pipeline=Pipeline(aggregation=EntitywiseQrQuantile(lipschitz=0.2)), subtitle=\"$ L = 0.2 $\"),\n",
    "]\n",
    "\n",
    "pool = ProcessPoolExecutor(max_workers=8)\n",
    "submissions = dict()\n",
    "for (idx, run) in enumerate(runs):\n",
    "    submissions[idx] = pool.submit(run_pipeline, pipeline=run[\"pipeline\"], criterion=\"largely_recommended\")\n",
    "for (idx, future) in submissions.items():\n",
    "    dir = Path(f\"./run_{idx:02}\")\n",
    "    dir.mkdir()\n",
    "    run = runs[idx]\n",
    "    pipeline = run[\"pipeline\"]\n",
    "    json.dump(pipeline.to_json(), (dir / \"pipeline.json\").open(\"w\"))\n",
    "    indiv_scores, global_scores = future.result()\n",
    "    indiv_scores.to_csv(dir / \"indiv_scores.csv\")\n",
    "    global_scores.to_csv(dir / \"global_scores.csv\")\n",
    "    plot_individual_scores(indiv_scores, subtitle=run[\"subtitle\"], dir=dir)\n",
    "    plot_global_scores(global_scores, subtitle=run[\"subtitle\"], dir=dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-ycqTiKvS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
