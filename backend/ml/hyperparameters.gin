# Hyperparameters configuration file 


# Options for production mode
ml_run.epochs = 60  # (max) number of training epochs of the algorithm
ml_run.resume = False  # wether to resume training or not
ml_run.compute_uncertainty = False  # wether to compute local uncertainty or not
                                        # (takes time)
ml_run.device = 'cpu'  # device used for computations ("cpu" or "cuda")


# Loss hyperparameters
Licchavi.nu_par = 5  # scaling parameter term ponderation
Licchavi.w_loc = 1  # generalisation term ponderation
Licchavi.w0_par = 1  # regularisation term ponderation
Licchavi.gamma = 1  # local regularisation term ponderation


# Training hyperparameters
Licchavi.lr_loc = 1  # learning rate of local models
Licchavi.lr_t = 0.005  # learning rate of t individual parameters
Licchavi.lr_s = 0.005  # learning rate of s individual parameters
Licchavi.lr_glob = 0.1  # learning rate of general model


# learning rate scheduler
_lr_schedule.lr_rush_duration = 50  # duration of "rush phase" (nb of epochs)
_lr_schedule.decay_rush = 0.97  # decay during "rush phase"
_lr_schedule.decay_fine = 1  # decay during fine tuning phase
_lr_schedule.min_lr_fine = 0.001  # minimum (local) learning rate

_lr_schedule.precision = 0.97 #proportion of parameters at eq for early stopping
_lr_schedule.epsilon = 0.1  # strength of equilibrium asked


# metrics to compute during training
Licchavi.metrics = [
    'loss_fit', 'loss_s', 'loss_gen', 'loss_reg', 'norm_glob', 'grad_sp', 
    'grad_norm',
    'norm_loc', 'diff_loc', 'diff_glob', 'diff_s'
] 
